- The more complex a model is, the more understanding it has, but less understandable it gets, so it appears.
- I propose to focus less on explainability of a model, as I see this in conflict with its expressive power, but more on its explain-ability - the power to express its knowledge, so that it can be understood by humans as well. 
- Consider [[Learning Compositional Rules via Neural Program Synthesis]][^@nyeLearningCompositionalRules2020] as an example: The model does the tideous work, but its output is a formalization of the learned/guessed structure that is interpretable by humans. 
- Similarly #computational-musicology could focus not only on building black-box models that, given their high #generative and #reconstruction performance, apparently understand something, but in a fuzzy and contrieved way, but utilize or even compose an expressive but more explicit code of a musical piece.
	- The non-neural approach in [[Generation of Musical Patterns through Operads]] does this: The proposed tree-view of the [[Operad]] composition makes explicit and unerstandable the recursive structure of (this specific) music as nested patterns. 
---
- The brain is in the same way not very well explainable (no stepping through of a composer's formula based on its neural activity). It is an example of really smart system, whichs smartness seems to be related to the fact that it is unintrospectible.
- Symbols emerge in the external interaction of complex neural systems, preimposing them may limit their ability, or they become so complex interacting that they lose their clusterification of meaning.
- But the brain produces explanations and even invents languages (like mathematics or music)[^@dehaeneSymbolsMentalPrograms2022].
- So we should research deep complex models that are not transparent at the neural level but communicate insight as a skillfull person would do - *brains* *outputting* *programs*[^1]
---
- As is shown for example in [[FIGARO]], engineered features, informed by simple music theory, still provide highly valuable contributions to latent music representations. 
- I would be interested in automatically generating music theory: *If music theoretical features are so valuable (and apparently they are) we should be able to construct models, that come up with them by themselves.* 
- Right now this is not the case, current machine learning techniques still fail at reproducing age-old music theoretical insights. This is a strong pointer that there is still an inductive something missing for achieving *intelligence*.


[^1]: In the hopes that they may not achieve similar complexity and start writing programs of their own and so on.

[^@dehaeneSymbolsMentalPrograms2022]: Dehaene, Stanislas, Fosca Al Roumi, Yair Lakretz, Samuel Planton, and Mathias Sablé-Meyer. 2022. “Symbols and Mental Programs: A Hypothesis about Human Singularity.” _Trends in Cognitive Sciences_ 26 (9): 751–66. [https://doi.org/gq9kx9](https://doi.org/gq9kx9).

[^@nyeLearningCompositionalRules2020]: Nye, Maxwell, Armando Solar-Lezama, Josh Tenenbaum, and Brenden M Lake. 2020. “Learning Compositional Rules via Neural Program Synthesis.” In _Advances in Neural Information Processing Systems_, 33:10832–42. Curran Associates, Inc. [https://doi.org/10.48550/arXiv.2003.05562](https://doi.org/10.48550/arXiv.2003.05562).

